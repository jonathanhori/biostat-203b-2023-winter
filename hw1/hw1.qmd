---
title: "Biostat 203B Homework 1"
subtitle: Due Jan 27 @ 11:59PM
author: Jonathan Hori - UID 305947261
format:
  html:
    theme: cosmo
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
knitr:
  opts_chunk: 
    cache: false    
    echo: true
    fig.align: 'center'
    fig.width: 6
    fig.height: 4
    message: FALSE
---

Display machine information for reproducibility:

```{r}
#| eval: true
sessionInfo()
```

## Q1. Git/GitHub

**No handwritten homework reports are accepted for this course.** We work with Git and GitHub. Efficient and abundant use of Git, e.g., frequent and well-documented commits, is an important criterion for grading your homework.

1.  Apply for the [Student Developer Pack](https://education.github.com/pack) at GitHub using your UCLA email. You'll get GitHub Pro account for free (unlimited public and private repositories).

2.  Create a **private** repository `biostat-203b-2023-winter` and add `Hua-Zhou` and `tomokiokuno0528` as your collaborators with write permission.

3.  Top directories of the repository should be `hw1`, `hw2`, ... Maintain two branches `master` and `develop`. The `develop` branch will be your main playground, the place where you develop solution (code) to homework problems and write up report. The `master` branch will be your presentation area. Submit your homework files (Quarto file `qmd`, `html` file converted by Quarto, all code and extra data sets to reproduce results) in `main` branch.

4.  After each homework due date, course reader and instructor will check out your `master` branch for grading. Tag each of your homework submissions with tag names `hw1`, `hw2`, ... Tagging time will be used as your submission time. That means if you tag your `hw1` submission after deadline, penalty points will be deducted for late submission.

5.  After this course, you can make this repository public and use it to demonstrate your skill sets on job market.

***DONE***

## Q2. Data ethics training

This exercise (and later in this course) uses the [MIMIC-IV data](https://mimic-iv.mit.edu), a freely accessible critical care database developed by the MIT Lab for Computational Physiology. Follow the instructions at <https://mimic.mit.edu/docs/gettingstarted/> to (1) complete the CITI `Data or Specimens Only Research` course and (2) obtain the PhysioNet credential for using the MIMIC-IV data. Display the verification links to your completion report and completion certificate here. (Hint: The CITI training takes a couple hours and the PhysioNet credentialing takes a couple days; do not leave it to the last minute.)

***ANSWER*** 

1. Completion report: https://www.citiprogram.org/verify/?ke564deb1-1db5-488a-94ea-5b256539f63c-53640198

2.  Completion certificate: https://www.citiprogram.org/verify/?w8447b5ed-b207-43c9-9f75-6668219eb831-53640198

------------------------------------------------------------------------

## Q3. Linux Shell Commands

1.  The `~/mimic` folder within the Docker container contains data sets from MIMIC-IV. Refer to the documentation <https://mimic.mit.edu/docs/iv/> for details of data files.\

```{bash}
#| eval: true
ls -l ~/mimic/
```

Please, do **not** put these data files into Git; they are big. Do **not** copy them into your directory. Do **not** decompress the gz data files. These create unnecessary big files on storage and are not big data friendly practices. Just read from the data folder `~/mimic` directly in following exercises.

Use Bash commands to answer following questions.

2.  Display the contents in the folders `core`, `hosp`, `icu`. Why are these data files distributed as `.csv.gz` files instead of `.csv` (comma separated values) files? Read the page <https://mimic.mit.edu/docs/iv/> to understand what's in each folder.

***ANSWER*** 

These files are distributed as `.csv.gz` files instead of `.csv` files because 
of their size - the `.csv.gz` files are `.csv` files compressed using gzip.

```{bash}
ls -l ~/mimic/core/
```

```{bash}
ls -l ~/mimic/hosp/
```

The `hosp` module contains data sourced from patient-level electronic health records. These records are hospital-wide.

```{bash}
ls -l ~/mimic/icu/
```

The `icu` module contains patient-level data sourced specifically from the ICU.

3.  Briefly describe what bash commands `zcat`, `zless`, `zmore`, and `zgrep` do.

***ANSWER***

Each of these bash commands are similar to the analogous commands without the `z-` 
prefix, but are used on files compressed by gzip. We are able to use these commands on the
compressed files without first decompressing them:  
- `zcat` displays the contents of a compressed file  
- `zless` displays the contents of a file as pages, allowing scrolling  
- `zmore` also paginates the contents of a file, only scrolling downward  
- `zgrep` allows searching of a compressed file and displays matching lines of the file  

For example, each command below does not decompress the mimic data:

```{bash}
zcat ~/mimic/hosp/diagnoses_icd.csv.gz | head
```
```{bash} 
zgrep V0251 ~/mimic/hosp/diagnoses_icd.csv.gz | head # diagnoses having code V0251
```

4.  What's the output of the following bash script?

```{bash}
#| eval: true
for datafile in ~/mimic/core/*.gz
do
  ls -l $datafile
done
```

***ANSWER***

The above bash script lists all the gzip-compressed files in the core module of 
the mimic data. 

Display the number of lines in each data file using a similar loop.

```{bash}
#| eval: false

# Core module
for datafile in ~/mimic/core/*.gz
do
  echo $datafile
  zcat $datafile | awk 'END { print NR }'
done
```

```{bash}
#| eval: false

# Hospital module
for datafile in ~/mimic/hosp/*.gz
do
  echo $datafile
  zcat $datafile | awk 'END { print NR }'
done
```

```{bash}
#| eval: false

# ICU module
for datafile in ~/mimic/icu/*.gz
do
  echo $datafile
  zcat $datafile | awk 'END { print NR }'
done
```

5.  Display the first few lines of `admissions.csv.gz`. How many rows are in this data file? How many unique patients (identified by `subject_id`) are in this data file? (Hint: combine Linux commands `zcat`, `head`/`tail`, `awk`, `sort`, `uniq`, `wc`, and so on.)

***ANSWER***
```{bash}
# First few lines:
zcat ~/mimic/core/admissions.csv.gz | head
```

We observe that the admissions data has a header, which we remove in the below calculations.

```{bash}
# Number of rows:
zcat ~/mimic/core/admissions.csv.gz | 
  tail +2 | awk 'END { print NR }'
```

```{bash}
# Unique patients:
zcat ~/mimic/core/admissions.csv.gz | 
  tail +2 | awk -F, '{print $1}' | sort | uniq -u | wc -l
```
There are 523,740 rows in the admissions dataset. There are 171,080 unique patients
constituting these admissions.


6.  What are the possible values taken by each of the variable `admission_type`, `admission_location`, `insurance`, and `insurance`? Also report the count for each unique value of these variables. (Hint: combine Linux commands `zcat`, `head`/`tail`, `awk`, `uniq -c`, `wc`, and so on.)

***ANSWER***  
The unique values for each variable with the counts of their appearances are 
below.
```{bash}
# Admission type
zcat ~/mimic/core/admissions.csv.gz| 
  tail +2 | awk -F, '{print $6}' | sort | uniq -c
```


```{bash}
# Admission location
zcat ~/mimic/core/admissions.csv.gz | 
  tail +2 | awk -F, '{print $7}' | sort | uniq -c
```
Note there are 60,435 rows with a missing admission location.

```{bash}
# Insurance
zcat ~/mimic/core/admissions.csv.gz | 
  tail +2 | awk -F, '{print $9}' | sort | uniq -c
```

```{bash}
# Ethnicity
zcat ~/mimic/core/admissions.csv.gz | 
  tail +2 | awk -F, '{print $12}' | sort | uniq -c
```


## Q4. Who's popular in Price and Prejudice

1.  You and your friend just have finished reading *Pride and Prejudice* by Jane Austen. Among the four main characters in the book, Elizabeth, Jane, Lydia, and Darcy, your friend thinks that Darcy was the most mentioned. You, however, are certain it was Elizabeth. Obtain the full text of the novel from <http://www.gutenberg.org/cache/epub/42671/pg42671.txt> and save to your local folder.

```{bash}
#| eval: false
wget -nc http://www.gutenberg.org/cache/epub/42671/pg42671.txt
```

Explain what `wget -nc` does. Do **not** put this text file `pg42671.txt` in Git. Complete the following loop to tabulate the number of times each of the four characters is mentioned using Linux commands.

***ANSWER***  
Running `wget -nc` retrieves and saves the file found at the url provided. Adding
the `-nc` command prevents the file from being re-downloaded if already present.

```{bash}
#| eval: true
wget -nc http://www.gutenberg.org/cache/epub/42671/pg42671.txt
for char in Elizabeth Jane Lydia Darcy
do
  echo $char:
  grep -o $char pg42671.txt | wc -l
done
```

2.  What's the difference between the following two commands?

```{bash}
#| eval: false
echo 'hello, world' > test1.txt
```

and

```{bash}
#| eval: false
echo 'hello, world' >> test2.txt
```


***ANSWER***  
In the first command above, a `test1.txt` file is created. If this command is run
again, it will be overwritten. In the second command, if the `test2.txt` file 
does not already exist it will be created, but if it does exist then "hello, world" 
is appended to the end of the file.

3.  Using your favorite text editor (e.g., `vi`), type the following and save the file as `middle.sh`:

```{bash eval=FALSE}
#!/bin/sh
# Select lines from the middle of a file.
# Usage: bash middle.sh filename end_line num_lines
head -n "$2" "$1" | tail -n "$3"
```

Using `chmod` to make the file executable by the owner, and run

```{bash}
#| eval: true
./middle.sh pg42671.txt 20 5
```

Explain the output. Explain the meaning of `"$1"`, `"$2"`, and `"$3"` in this 
shell script. Why do we need the first line of the shell script?

***ANSWER***  
In the above bash script, the `$1`, `$2`, and `$3` variables are referencing the
first, second, and third arguments to our script, respectively. Our script first
considers the head of the file provided by the first argument, up to the line 
number given by the second argument (20 in our case). Then it looks at the tail 
of this output, up to the number of lines given by the third argument. So the 
output we see above are lines 15 through 20 in the Pride and Prejudice `.txt` 
file.

We need the first line of the shell script to indicate what interpreter we would
like to execute our script with.


## Q5. More fun with Linux

Try following commands in Bash and interpret the results: `cal`, `cal 2021`, `cal 9 1752` (anything unusual?), `date`, `hostname`, `arch`, `uname -a`, `uptime`, `who am i`, `who`, `w`, `id`, `last | head`, `echo {con,pre}{sent,fer}{s,ed}`, `time sleep 5`, `history | tail`.

***ANSWER***  

Print a calendar of the current month.
```{bash}
cal
```

Print a calendar of the year 2021.
```{bash}
cal 2021
```

Print the monthly calendar for September 1752. It seems 12 dates are missing,
and that the cause is the adoption of the [Gregorian calendar by the British 
empire](https://en.wikipedia.org/wiki/Adoption_of_the_Gregorian_calendar).
```{bash}
cal 9 1752
```

Print the current date and time.

```{bash}
date
```


Print the hostname of my device.
```{bash}
hostname
```


Output the architecture of my device. It seems this machine is running AArch64.
```{bash}
arch
```


Output all the system information for my device. Using the `-a` option returns:
1) OS name  
2) network node  
3) OS release number  
4) system name  
5) OS version  
6) system hardware information  

```{bash}
uname -a
```


Display how long the current system has been running. 
```{bash}
uptime
```


Output which user is making these commands among logged in users
```{bash}
#who am i # No output in docker container.
whoami # Works in Ubuntu
```


Output all currently logged in users. Nothing outputs when running this command 
in the Docker container provided. A suspicion for this is because of the 
permissions avilable to the `rstuidio` user.
```{bash}
who # No output in docker container
```

Output all logged in users with the current process they are running. Again,
nothing outputs in the course Docker container.
```{bash}
w # No users returned in docker container
```


Output the user and group names and uids for the current user. 
```{bash}
id
```


Display all the users who have logged in (or out) of the system.

```{bash}
last | head 
```


Display all the permutations of the strings enclosed by the brackets. Strings 
are concatenated in the order of the brackets.
```{bash}
echo {con,pre}{sent,fer}{s,ed}
```

The `time` command executes the subsequent command given, and reports the real-, 
user- and system CPU time to execute this command. Here, we use it with the 
`sleep` command, which delays further shell execution for the given number of 
seconds. So the real-time output of slightly over 5 seconds makes sense.
```{bash}
time sleep 5
```

Return the last commands entered. Nothing is returned here. A possible reason 
for this is the way Quarto executes code chunks, and the `history` command might
not have access to the history from all code chunks together.
```{bash}
history | tail # No output
```

