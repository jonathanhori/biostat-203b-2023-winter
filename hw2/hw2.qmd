---
title: "Biostat 203B Homework 2"
subtitle: Due Feb 10 @ 11:59PM
author: Jonathan Hori - 305947261
format:
  html:
    theme: cosmo
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
knitr:
  opts_chunk: 
    cache: false    
    echo: true
    fig.align: 'center'
    fig.width: 6
    fig.height: 4
    message: FALSE
---

Display machine information for reproducibility:
```{r}
#| eval: true
sessionInfo()
```

Load necessary libraries (you can add more as needed).
```{r setup}
library(data.table)
library(lubridate)
library(R.utils)
library(tidyverse)
```

MIMIC data location
```{r}
mimic_path <- "~/mimic"
```

In this exercise, we use tidyverse (ggplot2, dplyr, etc) to explore the [MIMIC-IV](https://mimic.mit.edu/docs/iv/) data introduced in [homework 1](https://ucla-biostat-203b.github.io/2023winter/hw/hw1/hw1.html) and to build a cohort of ICU stays.

Display the contents of MIMIC data folder. 
```{r}
system(str_c("ls -l ", mimic_path, "/"), intern = TRUE)
system(str_c("ls -l ", mimic_path, "/core"), intern = TRUE)
system(str_c("ls -l ", mimic_path, "/hosp"), intern = TRUE)
system(str_c("ls -l ", mimic_path, "/icu"), intern = TRUE)
```

## Q1. `read.csv` (base R) vs `read_csv` (tidyverse) vs `fread` (data.table)

There are quite a few utilities in R for reading plain text data files. Let us test the speed of reading a moderate sized compressed csv file, `admissions.csv.gz`, by three programs: `read.csv` in base R, `read_csv` in tidyverse, and `fread` in the popular data.table package. 

Which function is fastest? Is there difference in the (default) parsed data types? (Hint: R function `system.time` measures run times.)

For later questions, we stick to the `read_csv` in tidyverse.

***ANSWER***
```{r}
admissions_filename <- str_c(mimic_path, "/core/admissions.csv.gz")

# Helper function to evaluate data reading
read_and_time_fileopen <- function(filename, read_fn) {
  print(
    system.time(data <- read_fn(filename))
    )
  str(data)
}
```

```{r}
# Timing read.csv
read_and_time_fileopen(admissions_filename, read.csv)
```

```{r}
# Timing read_csv
read_and_time_fileopen(admissions_filename, read_csv)
```

```{r}
# Timing fread
read_and_time_fileopen(admissions_filename, fread)
```

We see that `fread` takes the shortest amount of time to open the data, followed
by `read_csv`, with the slowest function being `read.csv`. 

There are sight differences in the default parsed data types among the functions.
In base R, `read.csv` appears to be the "dumbest" function, and makes no attempt
to process dates or to fill in missing values with `NA`s. However, both 
`read_csv` and `fread` do convert datetimes properly, and replace empty strings
with the constant `NA`. Aside from these more major differences, there is 
another small difference in reading integer values: `read.csv` and `fread` 
appear to read the integers in this dataset (subject and hospital ids, and
`hospital_expire_flag`) as integers, whereas `read_csv` reads these fields as
doubles.

## Q2. ICU stays

`icustays.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/icu/icustays/>) contains data about Intensive Care Units (ICU) stays. The first 10 lines are
```{r}
system(
  str_c(
    "zcat < ", 
    str_c(mimic_path, "/icu/icustays.csv.gz"), 
    " | head"
    ), 
  intern = TRUE
)
```

1. Import `icustays.csv.gz` as a tibble `icustays_tble`. 

2. How many unique `subject_id`? Can a `subject_id` have multiple ICU stays? 

3. Summarize the number of ICU stays per `subject_id` by graphs. 

4. For each `subject_id`, let's only keep the first ICU stay in the tibble `icustays_tble`. (Hint: `slice_min` and `slice_max` may take long. Think alternative ways to achieve the same function.)

***ANSWER***
```{r}
icustays_filename <- str_c(mimic_path, "/icu/icustays.csv.gz")

icustays_tble <- read_csv(icustays_filename)

icustays_tble %>%
  distinct(subject_id) %>% 
  count
```


```{r}
# Saving grouped data to reuse for multiple ggplots
grouped_stays <- icustays_tble %>% 
  group_by(subject_id) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))

grouped_stays %>% head

# Histogram of stays per patient
grouped_stays %>% 
  ggplot() +
  geom_bar(mapping = aes(x = count)) +
  labs(
    title = "Distribution of ICU stays per patient_id is positively skewed",
    x = "Stay count",
    y = "Patient count"
    )

# # Histogram of stays per patients having multiple stays
# grouped_stays %>% 
#   filter(count > 5) %>% 
#   ggplot() +
#     geom_bar(mapping = aes(x = count))
```

We observe that there are 53,150 unique patients in the ICU stays data. Patients
may appear more than once, with the patients having the most ICU stays appearing
over 30 times in the data. The distribution of ICU stay counts is highly 
positively skewed, with most patients only having one or a couple admissions.

```{r}
# Selecting only first ICU stay
first_icustays_tble <- icustays_tble %>% 
  group_by(subject_id) %>% 
  arrange(intime, .by_group=TRUE) %>% 
  slice(1)

first_icustays_tble
```



## Q3. `admission` data

Information of the patients admitted into hospital is available in `admissions.csv.gz`. See <https://mimic.mit.edu/docs/iv/modules/hosp/admissions/> for details of each field in this file. The first 10 lines are
```{r}
system(
  str_c(
    "zcat < ", 
    str_c(mimic_path, "/core/admissions.csv.gz"), 
    " | head"
    ), 
  intern = TRUE
)
```

1. Import `admissions.csv.gz` as a tibble `admissions_tble`.

2. Let's only keep the admissions that have a match in `icustays_tble` according to `subject_id` and `hadmi_id`.

3. Summarize the following variables by graphics. 

    - admission year  
    - admission month  
    - admission month day  
    - admission week day  
    - admission hour (anything unusual?)  
    - admission minute (anything unusual?)  
    - length of hospital stay (anything unusual?)    
    
    
***ANSWER***
```{r}
admissions_filename <- str_c(mimic_path, "/core/admissions.csv.gz")

admissions_tble <- read_csv(admissions_filename)
admissions_tble
```
Let's ensure we are considering patients in the icustays_tble.
```{r}
admissions_tble <- semi_join(admissions_tble, icustays_tble,
                             by = c("subject_id", "hadm_id"))
```

Now we process our date data on the smaller table.
```{r}
admissions_tble <- admissions_tble %>% 
  mutate(admit_year = year(admittime),
         admit_month = month(admittime, label=TRUE),
         admit_mday = mday(admittime),
         admit_wday = wday(admittime, label=TRUE),
         admit_hour = hour(admittime),
         admit_minute = minute(admittime),
         length_of_stay = as.duration(dischtime - admittime)
         )
admissions_tble
```


```{r}
# Admit year
admissions_tble %>% 
  ggplot() +
  geom_bar(mapping = aes(x = admit_year)) +
  labs(
    title = "Count of admissions by year",
    x = "Admit year",
    y = "Count"
  )
```
We see that admissions by month are roughly the same per month, with slighly 
fewer admissions in February.
```{r}
# Admit month
admissions_tble %>% 
  ggplot() +
  geom_bar(mapping = aes(x = admit_month)) +
  labs(
    title = "Count of admissions by month",
    x = "Admit month",
    y = "Count"
  )
```
Admissions by day of the month are also roughly constant over time, with a drop
on the 31st of the month. Since not every month has 31 days, it seems likely 
this is just an artifact of this source of bias.
```{r}
# Admit day of month
admissions_tble %>% 
  ggplot() +
  geom_bar(mapping = aes(x = admit_mday)) +
  labs(
    title = "Count of admissions by day of the month",
    x = "Day of month of admission",
    y = "Count"
  )
```
Admissions by weekday are also roughly constant.
```{r}
# Admit weekday
admissions_tble %>% 
  ggplot() +
  geom_bar(mapping = aes(x = admit_wday)) +
  labs(
    title = "Count of admissions by weekday",
    x = "Admit day",
    y = "Count"
  )
```
The number of admissions by hour varies widely over the course of a day. The 
mode occurs at hour 0, midnight. One suspects this is because of missing 
admission times defaulting to midnight on the date, rather than this 
representing a true trend in admissions. We also observe a clear increase in 
admissions in the afternoon, rising from roughly 10am until 6pm, when admissions
begin to decline slightly. It's unusual that there are more admissions at 7am 
than at other close times in the morning. One hypothesis for this (which we do 
not assess here) could be that some hospitals only open at 7am, and that 
patients arriving before then are recorded as being admitted at 7am.

```{r}
# Admit hour
admissions_tble %>% 
  ggplot() +
  geom_bar(mapping = aes(x = admit_hour)) +
  labs(
    title = "Count of admissions by hour",
    x = "Admit hour",
    y = "Count"
  )
```

The number of admissions per minute are roughly constant, with large exceptions
occurring at 0, 15, 30, and 45 minutes. This makes sense, as it is likely that
the admission time was entered after rounding to the nearest quarter of an hour
for simplicity at the hospital.

```{r}
# Admit minute
admissions_tble %>% 
  ggplot() +
  geom_bar(mapping = aes(x = admit_minute)) +
  labs(
    title = "Count of admissions by minute",
    x = "Admit minute",
    y = "Count"
  )
```

The below data is measured in hours. The length of stay distribution is highly 
positively skewed. It may be unusual that so many lengths are so long, as some
of the highest values have durations of years.

```{r}
# Length of stay
admissions_tble %>% 
  ggplot() +
  geom_freqpoly(mapping = aes(x = length_of_stay), binwidth = 3600) +
  labs(
    title = "Count of admissions by length of stay",
    x = "Length of stay",
    y = "Count"
  )

# admissions_tble %>% select(length_of_stay) %>% arrange(desc(length_of_stay))
```

## Q4. `patients` data

Patient information is available in `patients.csv.gz`. See <https://mimic.mit.edu/docs/iv/modules/hosp/patients/> for details of each field in this file. The first 10 lines are
```{r}
system(
  str_c(
    "zcat < ", 
    str_c(mimic_path, "/core/patients.csv.gz"), 
    " | head"
    ), 
  intern = TRUE
)
```

1. Import `patients.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/hosp/patients/>) as a tibble `patients_tble` and only keep the patients who have a match in `icustays_tble` (according to `subject_id`).

2. Summarize variables `gender` and `anchor_age`, and explain any patterns you see.

***ANSWER***
```{r}
patients_filename <- str_c(mimic_path, "/core/patients.csv.gz")
patients_tble <- read_csv(patients_filename)

patients_tble <- semi_join(patients_tble, icustays_tble,
                           on = "subject_id")
patients_tble
```

Summarizing anchor age:
```{r}
patients_tble %>% summarise(
  mean_age = mean(anchor_age),
  sd_age = sd(anchor_age),
  min_age = min(anchor_age),
  max_age = max(anchor_age),
  n_missing = sum(is.na(anchor_age)),
  range = max_age - min_age
)

patients_tble %>% 
  ggplot() + 
  geom_histogram(mapping = aes(x = anchor_age), bins = 73) # range of ages is 73

```
We see above that the youngest patient in our dataset is 18, and the oldest is 
91. From the histogram of ages, we can see that the number of patients increases
as age increases, with this trend reversing around age 65. After this age, the 
number of patients begins to decrease. 

Now summarizing gender:
```{r}
patients_tble %>% 
  group_by(gender) %>% 
  summarise(count = n(), 
            n_missing = sum(is.na(gender)))


patients_tble %>% 
  ggplot() +
  geom_bar(mapping = aes(x = anchor_age, fill=gender), position = "dodge") +
  labs(
    title = "Anchor Age distributions by gender"
  )
```

We observe that there are more males than females in this dataset, with 29,797 
males and 23,353 females. The shapes of age distributions per gender look 
roughly similar. Interestingly, the number of patients per age begins to decline 
for men after peaking around age 65, whereas the number of patients per age 
remains roughly constant as women get older, only declining at higher ages.


## Q5. Lab results

`labevents.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/hosp/labevents/>) contains all laboratory measurements for patients. The first 10 lines are
```{r}
system(
  str_c(
    "zcat < ", 
    str_c(mimic_path, "/hosp/labevents.csv.gz"), 
    " | head"
    ), 
  intern = TRUE
)
```
`d_labitems.csv.gz` is the dictionary of lab measurements. 
```{r}
system(
  str_c(
    "zcat < ", 
    str_c(mimic_path, "/hosp/d_labitems.csv.gz"), 
    " | head"
    ), 
  intern = TRUE
)
```

1. Find how many rows are in `labevents.csv.gz`.

2. We are interested in the lab measurements of creatinine (50912), potassium (50971), sodium (50983), chloride (50902), bicarbonate (50882), hematocrit (51221), white blood cell count (51301), and glucose (50931). Retrieve a subset of `labevents.csv.gz` only containing these items for the patients in `icustays_tble` as a tibble `labevents_tble`. 

    Hint: `labevents.csv.gz` is a data file too big to be read in by the `read_csv` function in its default setting. Utilize the `col_select` option in the `read_csv` function to reduce the memory burden. It took my computer 5-10 minutes to ingest this file. If your computer really has trouble importing `labevents.csv.gz`, you can import from the reduced data file `labevents_filtered_itemid.csv.gz`.

3. Further restrict `labevents_tble` to the first lab measurement during the ICU stay. 

4. Summarize the lab measurements by appropriate numerics and graphics. 

## Q6. Vitals from charted events

`chartevents.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/icu/chartevents/>) contains all the charted data available for a patient. During their ICU stay, the primary repository of a patientâ€™s information is their electronic chart. The `itemid` variable indicates a single measurement type in the database. The `value` variable is the value measured for `itemid`. The first 10 lines of `chartevents.csv.gz` are
```{r}
system(
  str_c(
    "zcat < ", 
    str_c(mimic_path, "/icu/chartevents.csv.gz"), 
    " | head"), 
  intern = TRUE
)
```
`d_items.csv.gz` (<https://mimic.mit.edu/docs/iv/modules/icu/d_items/>) is the dictionary for the `itemid` in `chartevents.csv.gz`. 
```{r}
system(
  str_c(
    "zcat < ", 
    str_c(mimic_path, "/icu/d_items.csv.gz"), 
    " | head"), 
  intern = TRUE
)
```

1. We are interested in the vitals for ICU patients: heart rate (220045), mean non-invasive blood pressure (220181), systolic non-invasive blood pressure (220179), body temperature in Fahrenheit (223761), and respiratory rate (220210). Retrieve a subset of `chartevents.csv.gz` only containing these items for the patients in `icustays_tble` as a tibble `chartevents_tble`.

    Hint: `chartevents.csv.gz` is a data file too big to be read in by the `read_csv` function in its default setting. Utilize the `col_select` option in the `read_csv` function to reduce the memory burden. It took my computer >15 minutes to ingest this file. If your computer really has trouble importing `chartevents.csv.gz`, you can import from the reduced data file `chartevents_filtered_itemid.csv.gz`.

2. Further restrict `chartevents_tble` to the first vital measurement during the ICU stay. 

3. Summarize these vital measurements by appropriate numerics and graphics. 

## Q7. Putting things together

Let us create a tibble `mimic_icu_cohort` for all ICU stays, where rows are the first ICU stay of each unique adult (age at admission > 18) and columns contain at least following variables  

- all variables in `icustays.csv.gz`  
- all variables in `admission.csv.gz`  
- all variables in `patients.csv.gz`  
- first lab measurements during ICU stay  
- first vital measurements during ICU stay
- an indicator variable `thirty_day_mort` whether the patient died within 30 days of hospital admission (30 day mortality)

## Q8. Exploratory data analysis (EDA)

Summarize following information using appropriate numerics or graphs.

- `thirty_day_mort` vs demographic variables (ethnicity, language, insurance, marital_status, gender, age at hospital admission)

- `thirty_day_mort` vs first lab measurements

- `thirty_day_mort` vs first vital measurements

- `thirty_day_mort` vs first ICU unit

